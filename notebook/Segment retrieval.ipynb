{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1e614d",
   "metadata": {},
   "source": [
    "# Segment retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "39fa37ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2534a24c",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "070a72da",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel1 = \"corpus_three_annot.xlsx\"\n",
    "excel2 = \"corpus_two_annot.xlsx\"\n",
    "corpus1 = pd.read_excel(excel1)\n",
    "corpus2 = pd.read_excel(excel2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c6c099",
   "metadata": {},
   "source": [
    "### 1. 1. Annotated corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b4c354f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght corpus 1 : 161\n"
     ]
    }
   ],
   "source": [
    "corpus1 = corpus1[[\"id_segment\", 'text_segment', \"relevance_label\", \"relevance_type_norm\"]]\n",
    "print(\"Lenght corpus 1 : {}\".format(len(corpus1.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bded9906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght corpus 2 : 169\n"
     ]
    }
   ],
   "source": [
    "corpus2 = corpus2[[\"id_segment\", 'text_segment', \"relevance_label\", \"relevance_type_norm\"]]\n",
    "print(\"Lenght corpus 2 : {}\".format(len(corpus2.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53472b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_corpus = pd.concat([corpus1, corpus2])\n",
    "len(annotated_corpus.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a023b31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   relevance_label\n",
       "0              218\n",
       "1               71\n",
       "2               41"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(annotated_corpus[\"relevance_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b9db6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_segment</th>\n",
       "      <th>text_segment</th>\n",
       "      <th>relevance_label</th>\n",
       "      <th>relevance_type_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-s2.0-S0301479717300713-main_226b</td>\n",
       "      <td>#text': '(Lambin et al., 2003)'}], '#text': 'W...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-s2.0-S0303243414001718-main_19b</td>\n",
       "      <td>#text': 'After the droughts in the 1970s and 1...</td>\n",
       "      <td>2</td>\n",
       "      <td>LULCC, DRIVERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-s2.0-S030438781000043X-mainext_313b</td>\n",
       "      <td>#text': 'Few investment opportunities are avai...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-s2.0-S095937809800003X-main_75b</td>\n",
       "      <td>#text': 'Pastoral production has often existed...</td>\n",
       "      <td>1</td>\n",
       "      <td>PRACTICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-s2.0-S0006320709005400-main_16b</td>\n",
       "      <td>#text': 'The forests of West and Central Afric...</td>\n",
       "      <td>2</td>\n",
       "      <td>LULC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id_segment  \\\n",
       "0     1-s2.0-S0301479717300713-main_226b   \n",
       "1      1-s2.0-S0303243414001718-main_19b   \n",
       "2  1-s2.0-S030438781000043X-mainext_313b   \n",
       "3      1-s2.0-S095937809800003X-main_75b   \n",
       "4      1-s2.0-S0006320709005400-main_16b   \n",
       "\n",
       "                                        text_segment  relevance_label  \\\n",
       "0  #text': '(Lambin et al., 2003)'}], '#text': 'W...                0   \n",
       "1  #text': 'After the droughts in the 1970s and 1...                2   \n",
       "2  #text': 'Few investment opportunities are avai...                0   \n",
       "3  #text': 'Pastoral production has often existed...                1   \n",
       "4  #text': 'The forests of West and Central Afric...                2   \n",
       "\n",
       "  relevance_type_norm  \n",
       "0                 NaN  \n",
       "1      LULCC, DRIVERS  \n",
       "2                 NaN  \n",
       "3           PRACTICES  \n",
       "4                LULC  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138a0cc1",
   "metadata": {},
   "source": [
    "### 1. 2. All corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a72e4d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corpus = pd.read_excel(\"all_corpus_processed.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ddf18b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20345"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_corpus.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8914bf08",
   "metadata": {},
   "source": [
    "### 1.3. Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9f5edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    # Use a regular expression to find and remove anything between curly braces\n",
    "    cleaned_text = re.sub(r'\\{.*?\\}', ' ', text)\n",
    "\n",
    "    # Use a regular expression to remove all occurrences of '#text':\n",
    "    cleaned_text = re.sub(r\"'#text':\", '', cleaned_text)\n",
    "\n",
    "    cleaned_text = re.sub(r\"'#text':\", '', cleaned_text)\n",
    "    # Use a regular expression to remove all occurrences of '@xmlns':\n",
    "    cleaned_text = re.sub(r\"'@xmlns':\", '', cleaned_text)\n",
    "\n",
    "    # Use a regular expression to remove all occurrences of '<variable>: {'\n",
    "    cleaned_text = re.sub(r\"'\\w+':\\s*\", ' ', cleaned_text)\n",
    "\n",
    "    # Remove any sequence of more than two special characters or spaces\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9 .%]+', ' ', cleaned_text)\n",
    "\n",
    "    # Clean up excessive spaces\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c8af7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_corpus['cleaned_text'] = annotated_corpus['text_segment'].apply(clean_text)\n",
    "all_corpus['cleaned_text'] = all_corpus['text_segment'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49e1097",
   "metadata": {},
   "source": [
    "## 2. Supervised classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f46e41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "tqdm.monitor_interval = 0\n",
    "tqdm.pandas()\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_predict, KFold, train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix, accuracy_score, cohen_kappa_score, f1_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15b53fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3594ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_corpus[\"label_encoded\"] = pd.Categorical(annotated_corpus[\"relevance_label\"], ordered=True).codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67b857b",
   "metadata": {},
   "source": [
    "#### LinearSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91e645a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texts to vectorize\n",
    "X = annotated_corpus['cleaned_text'].tolist() \n",
    "X = [x.lower() for x in X]\n",
    "Y = annotated_corpus['label_encoded'].tolist() \n",
    "\n",
    "# Initialize models\n",
    "svc_model = LinearSVC(class_weight='balanced')\n",
    "\n",
    "def calculate_metrics(model, X, y, cv= 5):\n",
    "    y_pred = cross_val_predict(model, X, y, cv=cv)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y, y_pred, average=None)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y, y_pred))\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f594d74",
   "metadata": {},
   "source": [
    "Default values for TF-IDF vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8464dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Metrics:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.82       218\n",
      "           1       0.34      0.14      0.20        71\n",
      "           2       0.82      0.34      0.48        41\n",
      "\n",
      "    accuracy                           0.69       330\n",
      "   macro avg       0.63      0.47      0.50       330\n",
      "weighted avg       0.65      0.69      0.64       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Convert texts to TF-IDF matrix\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "# Evaluate Linear SVC\n",
    "print(\"Linear SVC Metrics:\")\n",
    "svc_precision, svc_recall, svc_f1 = calculate_metrics(svc_model, X_tfidf, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a1322a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Metrics:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.83       218\n",
      "           1       0.52      0.20      0.29        71\n",
      "           2       0.77      0.24      0.37        41\n",
      "\n",
      "    accuracy                           0.71       330\n",
      "   macro avg       0.67      0.47      0.49       330\n",
      "weighted avg       0.69      0.71      0.65       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')  \n",
    "\n",
    "# Convert texts to TF-IDF matrix\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "# Evaluate Linear SVC\n",
    "print(\"Linear SVC Metrics:\")\n",
    "svc_precision, svc_recall, svc_f1 = calculate_metrics(svc_model, X_tfidf, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc153d1",
   "metadata": {},
   "source": [
    "#### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2aef039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['cleaned_text', 'label', '__index_level_0__'],\n",
      "        num_rows: 264\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['cleaned_text', 'label', '__index_level_0__'],\n",
      "        num_rows: 66\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "annotated_corpus[\"cleaned_text\"] = annotated_corpus[\"cleaned_text\"].astype(\"string\")\n",
    "annotated_corpus[\"label\"] = pd.Categorical(annotated_corpus[\"relevance_label\"], ordered=True).codes\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import ClassLabel\n",
    "\n",
    "dataset = Dataset.from_pandas(annotated_corpus[[\"cleaned_text\", \"label\"]])\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0bfa584a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\valentin/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at C:\\Users\\valentin/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\valentin/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\merges.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\valentin/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\valentin/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\valentin/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\valentin/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\valentin/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/264 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/66 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pretrained_model = \"bert-base-uncased\"\n",
    "pretrained_model = \"roberta-base\"\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "def tokenize_function(batch):\n",
    "    tokenized_batch = tokenizer(batch['cleaned_text'], padding=True, truncation=True, max_length=128)\n",
    "    return tokenized_batch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model, num_labels=3)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n",
    "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "176aa122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_metric = load_metric(\"f1\")\n",
    "from datasets import load_metric\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    my_metrics ={\n",
    "        \"accuracy\": accuracy_score(y_pred=predictions, y_true=labels),\n",
    "    \"F1\": f1_score(y_pred=predictions, y_true=labels, average = 'weighted')\n",
    "        }\n",
    "\n",
    "    classif_report = classification_report(predictions, labels, digits=2, output_dict = True)\n",
    "    all_metrics = df_scores_small(classif_report)\n",
    "    \n",
    "    all_metrics.to_csv(f'{filename}.csv')\n",
    "    return my_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dadd6971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: cleaned_text, __index_level_0__. If cleaned_text, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 264\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 165\n",
      "  Number of trainable parameters = 124647939\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='165' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [165/165 38:11, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.656272</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.620073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.647460</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.665308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.521572</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.770349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.752479</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.734754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.714733</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.754267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: cleaned_text, __index_level_0__. If cleaned_text, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: cleaned_text, __index_level_0__. If cleaned_text, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 8\n",
      "C:\\Users\\valentin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\valentin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\valentin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: cleaned_text, __index_level_0__. If cleaned_text, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: cleaned_text, __index_level_0__. If cleaned_text, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: cleaned_text, __index_level_0__. If cleaned_text, __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=165, training_loss=0.513590957179214, metrics={'train_runtime': 2299.7633, 'train_samples_per_second': 0.574, 'train_steps_per_second': 0.072, 'total_flos': 86827427850240.0, 'train_loss': 0.513590957179214, 'epoch': 5.0})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "\n",
    "def df_scores_small(classif_report):\n",
    "    cls = [x for x in classif_report.keys() if x not in ['accuracy', 'macro avg', 'weighted avg']]\n",
    "    dfs = []\n",
    "    for key in cls:\n",
    "        df = pd.DataFrame(classif_report[key], index=[key])\n",
    "        dfs.append(df)\n",
    "\n",
    "    final_df = pd.concat(dfs)\n",
    "    for key in ['macro avg', 'weighted avg']:\n",
    "        df = pd.DataFrame(classif_report[key], index=[key])\n",
    "        dfs.append(df)\n",
    "\n",
    "    final_df = pd.concat(dfs)\n",
    "    final_df['accuracy'] = classif_report['accuracy']\n",
    "\n",
    "    return(final_df)    \n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\", \n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=5,\n",
    "    #batch_size=16,\n",
    "    seed=42\n",
    "    )\n",
    "\n",
    "filename = \"cm_roberta\"\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8f59de82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to roberta_model\n",
      "Configuration saved in roberta_model\\config.json\n",
      "Model weights saved in roberta_model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"roberta_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3cb1acd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valentin\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:89: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(\"roberta_model\")\n",
    "clf = pipeline(\"text-classification\", model = classification_model, tokenizer=tokenizer, \n",
    "               truncation = True, max_length = 128, return_all_scores = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e191d46",
   "metadata": {},
   "source": [
    "## 3. Segment retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8b8d09",
   "metadata": {},
   "source": [
    "### 3.1. Random selection of segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0373d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corpus_match = all_corpus[all_corpus['Match'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f9af4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "all_sentences_match = all_corpus_match[\"cleaned_text\"].tolist()\n",
    "random.shuffle(all_sentences_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "74cd4ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences_match_eval = all_sentences_match[0:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaec619",
   "metadata": {},
   "source": [
    "### 3.2. Label predicition with custom trained RoBERTa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "68c060f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▊                                                                                 | 2/200 [00:00<00:24,  8.03it/s]\u001b[A\n",
      "  2%|█▋                                                                                | 4/200 [00:00<00:23,  8.33it/s]\u001b[A\n",
      "  3%|██▍                                                                               | 6/200 [00:00<00:25,  7.66it/s]\u001b[A\n",
      "  4%|██▊                                                                               | 7/200 [00:00<00:27,  7.10it/s]\u001b[A\n",
      "  4%|███▋                                                                              | 9/200 [00:01<00:24,  7.71it/s]\u001b[A\n",
      "  5%|████                                                                             | 10/200 [00:01<00:24,  7.90it/s]\u001b[A\n",
      "  6%|████▊                                                                            | 12/200 [00:01<00:21,  8.87it/s]\u001b[A\n",
      "  6%|█████▎                                                                           | 13/200 [00:01<00:21,  8.87it/s]\u001b[A\n",
      "  7%|█████▋                                                                           | 14/200 [00:01<00:20,  9.04it/s]\u001b[A\n",
      "  8%|██████▍                                                                          | 16/200 [00:01<00:19,  9.58it/s]\u001b[A\n",
      "  8%|██████▉                                                                          | 17/200 [00:01<00:19,  9.33it/s]\u001b[A\n",
      " 10%|███████▋                                                                         | 19/200 [00:02<00:18,  9.54it/s]\u001b[A\n",
      " 10%|████████▌                                                                        | 21/200 [00:02<00:16, 10.63it/s]\u001b[A\n",
      " 12%|█████████▎                                                                       | 23/200 [00:02<00:17,  9.91it/s]\u001b[A\n",
      " 12%|██████████▏                                                                      | 25/200 [00:02<00:17, 10.25it/s]\u001b[A\n",
      " 14%|██████████▉                                                                      | 27/200 [00:02<00:16, 10.33it/s]\u001b[A\n",
      " 14%|███████████▋                                                                     | 29/200 [00:03<00:21,  7.95it/s]\u001b[A\n",
      " 16%|████████████▌                                                                    | 31/200 [00:03<00:18,  9.37it/s]\u001b[A\n",
      " 16%|█████████████▎                                                                   | 33/200 [00:03<00:15, 10.78it/s]\u001b[A\n",
      " 18%|██████████████▏                                                                  | 35/200 [00:03<00:14, 11.75it/s]\u001b[A\n",
      " 18%|██████████████▉                                                                  | 37/200 [00:03<00:13, 12.51it/s]\u001b[A\n",
      " 20%|███████████████▊                                                                 | 39/200 [00:03<00:11, 14.06it/s]\u001b[A\n",
      " 20%|████████████████▌                                                                | 41/200 [00:04<00:11, 14.05it/s]\u001b[A\n",
      " 22%|█████████████████▍                                                               | 43/200 [00:04<00:15,  9.96it/s]\u001b[A\n",
      " 22%|██████████████████▏                                                              | 45/200 [00:04<00:13, 11.08it/s]\u001b[A\n",
      " 24%|███████████████████                                                              | 47/200 [00:04<00:12, 12.33it/s]\u001b[A\n",
      " 24%|███████████████████▊                                                             | 49/200 [00:04<00:13, 11.15it/s]\u001b[A\n",
      " 26%|████████████████████▋                                                            | 51/200 [00:05<00:13, 10.70it/s]\u001b[A\n",
      " 26%|█████████████████████▍                                                           | 53/200 [00:05<00:12, 11.39it/s]\u001b[A\n",
      " 28%|██████████████████████▎                                                          | 55/200 [00:05<00:11, 12.10it/s]\u001b[A\n",
      " 28%|███████████████████████                                                          | 57/200 [00:05<00:14,  9.98it/s]\u001b[A\n",
      " 30%|███████████████████████▉                                                         | 59/200 [00:05<00:13, 10.25it/s]\u001b[A\n",
      " 30%|████████████████████████▋                                                        | 61/200 [00:06<00:13, 10.66it/s]\u001b[A\n",
      " 32%|█████████████████████████▌                                                       | 63/200 [00:06<00:11, 12.17it/s]\u001b[A\n",
      " 32%|██████████████████████████▎                                                      | 65/200 [00:06<00:10, 12.41it/s]\u001b[A\n",
      " 34%|███████████████████████████▏                                                     | 67/200 [00:06<00:12, 10.89it/s]\u001b[A\n",
      " 35%|████████████████████████████▎                                                    | 70/200 [00:06<00:10, 11.82it/s]\u001b[A\n",
      " 36%|█████████████████████████████▏                                                   | 72/200 [00:06<00:10, 12.33it/s]\u001b[A\n",
      " 37%|█████████████████████████████▉                                                   | 74/200 [00:07<00:11, 10.69it/s]\u001b[A\n",
      " 38%|██████████████████████████████▊                                                  | 76/200 [00:07<00:11, 10.53it/s]\u001b[A\n",
      " 39%|███████████████████████████████▌                                                 | 78/200 [00:07<00:12,  9.71it/s]\u001b[A\n",
      " 40%|████████████████████████████████▍                                                | 80/200 [00:07<00:11, 10.88it/s]\u001b[A\n",
      " 41%|█████████████████████████████████▏                                               | 82/200 [00:07<00:09, 11.91it/s]\u001b[A\n",
      " 42%|██████████████████████████████████                                               | 84/200 [00:08<00:09, 11.95it/s]\u001b[A\n",
      " 43%|██████████████████████████████████▊                                              | 86/200 [00:08<00:11,  9.81it/s]\u001b[A\n",
      " 44%|███████████████████████████████████▋                                             | 88/200 [00:08<00:10, 10.61it/s]\u001b[A\n",
      " 45%|████████████████████████████████████▍                                            | 90/200 [00:08<00:09, 11.33it/s]\u001b[A\n",
      " 46%|█████████████████████████████████████▎                                           | 92/200 [00:08<00:09, 11.20it/s]\u001b[A\n",
      " 47%|██████████████████████████████████████                                           | 94/200 [00:08<00:08, 12.28it/s]\u001b[A\n",
      " 48%|██████████████████████████████████████▉                                          | 96/200 [00:09<00:08, 12.00it/s]\u001b[A\n",
      " 49%|███████████████████████████████████████▋                                         | 98/200 [00:09<00:07, 13.43it/s]\u001b[A\n",
      " 50%|████████████████████████████████████████                                        | 100/200 [00:09<00:07, 12.99it/s]\u001b[A\n",
      " 51%|████████████████████████████████████████▊                                       | 102/200 [00:09<00:07, 12.55it/s]\u001b[A\n",
      " 52%|█████████████████████████████████████████▌                                      | 104/200 [00:09<00:06, 13.72it/s]\u001b[A\n",
      " 53%|██████████████████████████████████████████▍                                     | 106/200 [00:09<00:06, 13.56it/s]\u001b[A\n",
      " 54%|███████████████████████████████████████████▏                                    | 108/200 [00:09<00:06, 14.63it/s]\u001b[A\n",
      " 55%|████████████████████████████████████████████                                    | 110/200 [00:10<00:06, 14.73it/s]\u001b[A\n",
      " 56%|████████████████████████████████████████████▊                                   | 112/200 [00:10<00:07, 12.46it/s]\u001b[A\n",
      " 57%|█████████████████████████████████████████████▌                                  | 114/200 [00:10<00:06, 12.86it/s]\u001b[A\n",
      " 58%|██████████████████████████████████████████████▍                                 | 116/200 [00:10<00:06, 13.52it/s]\u001b[A\n",
      " 59%|███████████████████████████████████████████████▏                                | 118/200 [00:10<00:05, 14.55it/s]\u001b[A\n",
      " 60%|████████████████████████████████████████████████                                | 120/200 [00:10<00:05, 13.46it/s]\u001b[A\n",
      " 61%|████████████████████████████████████████████████▊                               | 122/200 [00:10<00:05, 14.46it/s]\u001b[A\n",
      " 62%|█████████████████████████████████████████████████▌                              | 124/200 [00:11<00:05, 15.17it/s]\u001b[A\n",
      " 63%|██████████████████████████████████████████████████▍                             | 126/200 [00:11<00:04, 16.28it/s]\u001b[A\n",
      " 64%|███████████████████████████████████████████████████▌                            | 129/200 [00:11<00:03, 18.40it/s]\u001b[A\n",
      " 66%|████████████████████████████████████████████████████▍                           | 131/200 [00:11<00:04, 16.24it/s]\u001b[A\n",
      " 66%|█████████████████████████████████████████████████████▏                          | 133/200 [00:11<00:05, 12.51it/s]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████                          | 135/200 [00:11<00:05, 12.30it/s]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████▊                         | 137/200 [00:12<00:05, 12.02it/s]\u001b[A\n",
      " 70%|███████████████████████████████████████████████████████▌                        | 139/200 [00:12<00:04, 12.68it/s]\u001b[A\n",
      " 71%|████████████████████████████████████████████████████████▊                       | 142/200 [00:12<00:05, 11.20it/s]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████▌                      | 144/200 [00:12<00:04, 11.57it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████▍                     | 146/200 [00:12<00:04, 11.65it/s]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████████▏                    | 148/200 [00:12<00:04, 12.67it/s]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████████                    | 150/200 [00:13<00:03, 13.15it/s]\u001b[A\n",
      " 76%|████████████████████████████████████████████████████████████▊                   | 152/200 [00:13<00:03, 13.92it/s]\u001b[A\n",
      " 77%|█████████████████████████████████████████████████████████████▌                  | 154/200 [00:13<00:03, 13.26it/s]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████████▍                 | 156/200 [00:13<00:03, 12.94it/s]\u001b[A\n",
      " 79%|███████████████████████████████████████████████████████████████▏                | 158/200 [00:13<00:03, 13.83it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████████                | 160/200 [00:13<00:03, 12.75it/s]\u001b[A\n",
      " 81%|████████████████████████████████████████████████████████████████▊               | 162/200 [00:14<00:03,  9.71it/s]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████▌              | 164/200 [00:14<00:03, 11.06it/s]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████████▍             | 166/200 [00:14<00:03, 11.01it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████████▏            | 168/200 [00:14<00:02, 11.63it/s]\u001b[A\n",
      " 85%|████████████████████████████████████████████████████████████████████            | 170/200 [00:14<00:02, 12.41it/s]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████▊           | 172/200 [00:14<00:02, 11.88it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████████▌          | 174/200 [00:15<00:02, 12.97it/s]\u001b[A\n",
      " 88%|██████████████████████████████████████████████████████████████████████▍         | 176/200 [00:15<00:01, 13.41it/s]\u001b[A\n",
      " 89%|███████████████████████████████████████████████████████████████████████▏        | 178/200 [00:15<00:01, 13.98it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████████        | 180/200 [00:15<00:01, 15.01it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████▊       | 182/200 [00:15<00:01, 14.86it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▌      | 184/200 [00:15<00:01, 10.96it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████████▍     | 186/200 [00:16<00:01, 11.39it/s]\u001b[A\n",
      " 94%|███████████████████████████████████████████████████████████████████████████▏    | 188/200 [00:16<00:01, 11.79it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████████    | 190/200 [00:16<00:00, 12.96it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▊   | 192/200 [00:16<00:00, 13.46it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████████████████████████████████████████▌  | 194/200 [00:16<00:00, 13.97it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████▍ | 196/200 [00:16<00:00, 14.40it/s]\u001b[A\n",
      " 99%|███████████████████████████████████████████████████████████████████████████████▏| 198/200 [00:16<00:00, 13.76it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:17<00:00, 11.74it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "rows = list()\n",
    "for text in tqdm(all_sentences_match_eval, total=len(all_sentences_match_eval)):\n",
    "    prediction = clf(text)[0]\n",
    "    max_prob = max(prediction, key=lambda x: x['score'])\n",
    "    label = prediction.index(max_prob)\n",
    "    rows.append((label, prediction[1]['score'],prediction[2]['score']))\n",
    "    \n",
    "predictions_roberta  = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "42c5de7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    118\n",
       "1     49\n",
       "2     33\n",
       "Name: pred_label, dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_roberta.columns = ['pred_label', 'prob_label_1', 'prob_label_2']\n",
    "predictions_roberta['pred_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b883a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = pd.DataFrame({\"cleaned_text\": all_sentences_match_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "869fb8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = pd.concat([df_analysis, predictions_roberta], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e296b4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>prob_label_1</th>\n",
       "      <th>prob_label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cause of land use and land cover changes i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.853471</td>\n",
       "      <td>0.120585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One quarter of the millipede species recorded ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066776</td>\n",
       "      <td>0.003415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We started with the literature analysis to rec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.001459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though open questions were intentionally ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.001532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Next to this the historical time series of lan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.001501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Finally we used the mosaics from the 2 differe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004369</td>\n",
       "      <td>0.001450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Having explored the state of the literature an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006992</td>\n",
       "      <td>0.001289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>We use the term urban sprawl to describe a spe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016153</td>\n",
       "      <td>0.001613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>C 3 crops are expected to produce more however...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060429</td>\n",
       "      <td>0.003117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>The production of this crop is encouraged by t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.001708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          cleaned_text  pred_label  \\\n",
       "0    The cause of land use and land cover changes i...           1   \n",
       "1    One quarter of the millipede species recorded ...           0   \n",
       "2    We started with the literature analysis to rec...           0   \n",
       "3    Even though open questions were intentionally ...           0   \n",
       "4    Next to this the historical time series of lan...           0   \n",
       "..                                                 ...         ...   \n",
       "195  Finally we used the mosaics from the 2 differe...           0   \n",
       "196  Having explored the state of the literature an...           0   \n",
       "197  We use the term urban sprawl to describe a spe...           0   \n",
       "198  C 3 crops are expected to produce more however...           0   \n",
       "199  The production of this crop is encouraged by t...           0   \n",
       "\n",
       "     prob_label_1  prob_label_2  \n",
       "0        0.853471      0.120585  \n",
       "1        0.066776      0.003415  \n",
       "2        0.004605      0.001459  \n",
       "3        0.005202      0.001532  \n",
       "4        0.004718      0.001501  \n",
       "..            ...           ...  \n",
       "195      0.004369      0.001450  \n",
       "196      0.006992      0.001289  \n",
       "197      0.016153      0.001613  \n",
       "198      0.060429      0.003117  \n",
       "199      0.014696      0.001708  \n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2f02990e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label : 2\n",
      "The types of land on which bow occur farmland and degraded savanna increased in northern Benin by 5.4% per year during the period 1975 1990 and 9.5% per year during the periods 1990 2010 while the natural vegetation forest woodland and tree savanna decreased by the same amount\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "Thus farmland persists and increases each year at the expense of forest woodland and tree savanna . The area of natural vegetation forest woodland and tree savanna that was considered degraded increased by 4.1% between the first and the second time periods i.e\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "About 8362.44 ha of tree savanna was converted into shrub savanna and 2605.5 ha into woodland respectively\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "The decrease in rainfall has been associated with a concentration of the cultivation of the sandy soils on the dune\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "The very strong increase 425% in the extent area of sand dunes Aeolian deposits and the over 50% decrease in area of undisturbed forest gave strong pointers to the land resources loss. http www.tei c.org ns 1.0 DISCUSSION The increasing down south march of the Sahara desert through the Sahelian zone of Nigeria is leading to the opening up of more natural forests for cultivation and grazing in the guinea savannah and rainforest zones\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "However conflicting hypotheses have been reported on the one hand an expansion into native savanna and intensification fertilizer of cropland cultivation and on the other hand agricultural land abandonment caused by e.g. the civil war in Sudan may both contribute to the observed positive trends\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "In addition the increase in population growth rate has also led to an increase in food consumption and food production explaining the expansion of land use and coherent with a decline of the vegetative areas savanna herbaceous savanna forest and evergreen forest\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "Similarly rainfall in the cloud forests of Costa Rica is sensitive to upwind vegetative cover\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "During the fallow period the fallow fields serve as a source for firewood and as grazing land which is the reason for their very low woody vegetation cover in 2011 Fig\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "The decline in dense forest over the 29 year period was similar to what was recorded for the entire country between 1980 and 1985\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "despite the rainfall deficit due to the increase in cropland at the expense of forest Fig\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "More scattered agriculture is found at the same latitudes over the remaining parts of the Sudano Sahel\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "According to the desertifi cation in the Sahel is due to the deforestation and the overgrazing. type bibr Kiema et al\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "Most of the savannah lands has the fertility issues P13 And given the fact that a lot of the soils in most of these areas are also shallow\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "These losses in water bodies in the arid region were much larger than the losses i.e. 5.6% 10.2% and 15.7% that we observed in the entire West African subcontinent during the same periods respectively see Table in the Appendix A . The vast majority of the gains in water bodies observed in the humid region were at the expense of other vegetation 0.5% and 0.5% forestland 0.9% and 0.9% cropland 0.7% and 0.7% and wetland 4.6% and 4.2% in respectively see Table in the Appendix A\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "Perennial grasses in the southern zone are further protected from short fallow cultivation because Andropogon spp\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "The drier region of Sri Lanka north and east will experience huge losses in agriculture compared to the cooler central highland region the output of which is expected to remain the same or even increase with rising temperatures\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "Forest galleries could be confused with savannas and open forests in the dry season when the vegetation index is low. The forest galleries in the classified forest of Dogo K tou as shown in Figure bring together the wooded stands that run along the river Ou m and its tributaries\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "Given the fact that all arable land was under human management in the Fakara region prior to 2000 it can be assumed that the observed change in the percentage of cropped area is caused by a change in the crop fallow cycle towards less fallowed and more cropped fields during the period studied. Although no greening was observed in our study area these findings should be considered in the greening Sahel debate\n",
      "_____________________________________________\n",
      "Label : 2\n",
      "The Lake Chad basin which was the largest endorheic basin in the world experienced dramatic changes in terms of water area\n",
      "_____________________________________________\n"
     ]
    }
   ],
   "source": [
    "df_analysis_sorted = df_analysis.sort_values(by=['pred_label','prob_label_2'], ascending=False)\n",
    "for i in range(20) :\n",
    "    print(\"Label : {}\".format(df_analysis_sorted.iloc[i]['pred_label']))\n",
    "    print(df_analysis_sorted.iloc[i]['cleaned_text'])\n",
    "    print('_____________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da2794e",
   "metadata": {},
   "source": [
    "### 3.3. Semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "26e99832",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_sentences = annotated_corpus[annotated_corpus[\"label\"]==2][\"cleaned_text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "639c328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "be9f2d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\valentin/.cache\\torch\\sentence_transformers\\roberta-base. Creating a new one with MEAN pooling.\n",
      "loading configuration file C:\\Users\\valentin/.cache\\torch\\sentence_transformers\\roberta-base\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"C:\\\\Users\\\\valentin/.cache\\\\torch\\\\sentence_transformers\\\\roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file C:\\Users\\valentin/.cache\\torch\\sentence_transformers\\roberta-base\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at C:\\Users\\valentin/.cache\\torch\\sentence_transformers\\roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of RobertaModel were initialized from the model checkpoint at C:\\Users\\valentin/.cache\\torch\\sentence_transformers\\roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaModel for predictions without further training.\n",
      "loading configuration file C:\\Users\\valentin/.cache\\torch\\sentence_transformers\\roberta-base\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"C:\\\\Users\\\\valentin/.cache\\\\torch\\\\sentence_transformers\\\\roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file C:\\Users\\valentin/.cache\\torch\\sentence_transformers\\roberta-base\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"C:\\\\Users\\\\valentin/.cache\\\\torch\\\\sentence_transformers\\\\roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▍                                                                                 | 1/200 [00:03<13:12,  3.98s/it]\u001b[A\n",
      "  1%|▊                                                                                 | 2/200 [00:07<12:19,  3.73s/it]\u001b[A\n",
      "  2%|█▏                                                                                | 3/200 [00:11<11:59,  3.65s/it]\u001b[A\n",
      "  2%|█▋                                                                                | 4/200 [00:14<12:13,  3.74s/it]\u001b[A\n",
      "  2%|██                                                                                | 5/200 [00:18<12:18,  3.79s/it]\u001b[A\n",
      "  3%|██▍                                                                               | 6/200 [00:22<11:45,  3.64s/it]\u001b[A\n",
      "  4%|██▊                                                                               | 7/200 [00:25<11:50,  3.68s/it]\u001b[A\n",
      "  4%|███▎                                                                              | 8/200 [00:29<11:54,  3.72s/it]\u001b[A\n",
      "  4%|███▋                                                                              | 9/200 [00:33<11:33,  3.63s/it]\u001b[A\n",
      "  5%|████                                                                             | 10/200 [00:36<11:11,  3.53s/it]\u001b[A\n",
      "  6%|████▍                                                                            | 11/200 [00:39<10:54,  3.46s/it]\u001b[A\n",
      "  6%|████▊                                                                            | 12/200 [00:43<10:39,  3.40s/it]\u001b[A\n",
      "  6%|█████▎                                                                           | 13/200 [00:46<10:51,  3.49s/it]\u001b[A\n",
      "  7%|█████▋                                                                           | 14/200 [00:50<11:17,  3.64s/it]\u001b[A\n",
      "  8%|██████                                                                           | 15/200 [00:54<10:52,  3.53s/it]\u001b[A\n",
      "  8%|██████▍                                                                          | 16/200 [00:57<10:54,  3.56s/it]\u001b[A\n",
      "  8%|██████▉                                                                          | 17/200 [01:01<10:48,  3.54s/it]\u001b[A\n",
      "  9%|███████▎                                                                         | 18/200 [01:04<10:39,  3.52s/it]\u001b[A\n",
      " 10%|███████▋                                                                         | 19/200 [01:07<10:19,  3.42s/it]\u001b[A\n",
      " 10%|████████                                                                         | 20/200 [01:11<10:05,  3.36s/it]\u001b[A\n",
      " 10%|████████▌                                                                        | 21/200 [01:14<09:49,  3.29s/it]\u001b[A\n",
      " 11%|████████▉                                                                        | 22/200 [01:17<09:44,  3.28s/it]\u001b[A\n",
      " 12%|█████████▎                                                                       | 23/200 [01:21<10:12,  3.46s/it]\u001b[A\n",
      " 12%|█████████▋                                                                       | 24/200 [01:24<10:02,  3.42s/it]\u001b[A\n",
      " 12%|██████████▏                                                                      | 25/200 [01:27<09:51,  3.38s/it]\u001b[A\n",
      " 13%|██████████▌                                                                      | 26/200 [01:31<09:37,  3.32s/it]\u001b[A\n",
      " 14%|██████████▉                                                                      | 27/200 [01:34<09:25,  3.27s/it]\u001b[A\n",
      " 14%|███████████▎                                                                     | 28/200 [01:37<09:34,  3.34s/it]\u001b[A\n",
      " 14%|███████████▋                                                                     | 29/200 [01:41<09:35,  3.36s/it]\u001b[A\n",
      " 15%|████████████▏                                                                    | 30/200 [01:44<09:23,  3.32s/it]\u001b[A\n",
      " 16%|████████████▌                                                                    | 31/200 [01:47<09:12,  3.27s/it]\u001b[A\n",
      " 16%|████████████▉                                                                    | 32/200 [01:51<09:27,  3.38s/it]\u001b[A\n",
      " 16%|█████████████▎                                                                   | 33/200 [01:54<09:42,  3.49s/it]\u001b[A\n",
      " 17%|█████████████▊                                                                   | 34/200 [01:58<09:32,  3.45s/it]\u001b[A\n",
      " 18%|██████████████▏                                                                  | 35/200 [02:01<09:31,  3.47s/it]\u001b[A\n",
      " 18%|██████████████▌                                                                  | 36/200 [02:05<09:36,  3.51s/it]\u001b[A\n",
      " 18%|██████████████▉                                                                  | 37/200 [02:08<09:15,  3.41s/it]\u001b[A\n",
      " 19%|███████████████▍                                                                 | 38/200 [02:11<09:04,  3.36s/it]\u001b[A\n",
      " 20%|███████████████▊                                                                 | 39/200 [02:15<08:58,  3.34s/it]\u001b[A\n",
      " 20%|████████████████▏                                                                | 40/200 [02:18<09:00,  3.38s/it]\u001b[A\n",
      " 20%|████████████████▌                                                                | 41/200 [02:21<08:55,  3.37s/it]\u001b[A\n",
      " 21%|█████████████████                                                                | 42/200 [02:25<08:51,  3.36s/it]\u001b[A\n",
      " 22%|█████████████████▍                                                               | 43/200 [02:28<08:55,  3.41s/it]\u001b[A\n",
      " 22%|█████████████████▊                                                               | 44/200 [02:32<08:58,  3.45s/it]\u001b[A\n",
      " 22%|██████████████████▏                                                              | 45/200 [02:35<08:50,  3.42s/it]\u001b[A\n",
      " 23%|██████████████████▋                                                              | 46/200 [02:38<08:36,  3.35s/it]\u001b[A\n",
      " 24%|███████████████████                                                              | 47/200 [02:42<08:25,  3.30s/it]\u001b[A\n",
      " 24%|███████████████████▍                                                             | 48/200 [02:45<08:24,  3.32s/it]\u001b[A\n",
      " 24%|███████████████████▊                                                             | 49/200 [02:49<08:37,  3.43s/it]\u001b[A\n",
      " 25%|████████████████████▎                                                            | 50/200 [02:52<08:28,  3.39s/it]\u001b[A\n",
      " 26%|████████████████████▋                                                            | 51/200 [02:55<08:19,  3.35s/it]\u001b[A\n",
      " 26%|█████████████████████                                                            | 52/200 [02:58<08:08,  3.30s/it]\u001b[A\n",
      " 26%|█████████████████████▍                                                           | 53/200 [03:02<08:30,  3.47s/it]\u001b[A\n",
      " 27%|█████████████████████▊                                                           | 54/200 [03:06<08:54,  3.66s/it]\u001b[A\n",
      " 28%|██████████████████████▎                                                          | 55/200 [03:10<08:54,  3.69s/it]\u001b[A\n",
      " 28%|██████████████████████▋                                                          | 56/200 [03:14<08:41,  3.62s/it]\u001b[A\n",
      " 28%|███████████████████████                                                          | 57/200 [03:17<08:13,  3.45s/it]\u001b[A\n",
      " 29%|███████████████████████▍                                                         | 58/200 [03:20<08:00,  3.38s/it]\u001b[A\n",
      " 30%|███████████████████████▉                                                         | 59/200 [03:23<07:47,  3.32s/it]\u001b[A\n",
      " 30%|████████████████████████▎                                                        | 60/200 [03:26<07:35,  3.25s/it]\u001b[A\n",
      " 30%|████████████████████████▋                                                        | 61/200 [03:29<07:31,  3.25s/it]\u001b[A\n",
      " 31%|█████████████████████████                                                        | 62/200 [03:33<07:26,  3.24s/it]\u001b[A\n",
      " 32%|█████████████████████████▌                                                       | 63/200 [03:36<07:31,  3.30s/it]\u001b[A\n",
      " 32%|█████████████████████████▉                                                       | 64/200 [03:39<07:29,  3.30s/it]\u001b[A\n",
      " 32%|██████████████████████████▎                                                      | 65/200 [03:43<07:22,  3.27s/it]\u001b[A\n",
      " 33%|██████████████████████████▋                                                      | 66/200 [03:46<07:23,  3.31s/it]\u001b[A\n",
      " 34%|███████████████████████████▏                                                     | 67/200 [03:49<07:15,  3.27s/it]\u001b[A\n",
      " 34%|███████████████████████████▌                                                     | 68/200 [03:52<07:02,  3.20s/it]\u001b[A\n",
      " 34%|███████████████████████████▉                                                     | 69/200 [03:56<07:11,  3.29s/it]\u001b[A\n",
      " 35%|████████████████████████████▎                                                    | 70/200 [03:59<07:22,  3.41s/it]\u001b[A\n",
      " 36%|████████████████████████████▊                                                    | 71/200 [04:03<07:33,  3.51s/it]\u001b[A\n",
      " 36%|█████████████████████████████▏                                                   | 72/200 [04:07<07:56,  3.72s/it]\u001b[A\n",
      " 36%|█████████████████████████████▌                                                   | 73/200 [04:11<08:10,  3.86s/it]\u001b[A\n",
      " 37%|█████████████████████████████▉                                                   | 74/200 [04:15<07:55,  3.77s/it]\u001b[A\n",
      " 38%|██████████████████████████████▍                                                  | 75/200 [04:18<07:34,  3.64s/it]\u001b[A\n",
      " 38%|██████████████████████████████▊                                                  | 76/200 [04:22<07:23,  3.58s/it]\u001b[A\n",
      " 38%|███████████████████████████████▏                                                 | 77/200 [04:25<07:08,  3.49s/it]\u001b[A\n",
      " 39%|███████████████████████████████▌                                                 | 78/200 [04:28<06:57,  3.42s/it]\u001b[A\n",
      " 40%|███████████████████████████████▉                                                 | 79/200 [04:32<06:46,  3.36s/it]\u001b[A\n",
      " 40%|████████████████████████████████▍                                                | 80/200 [04:36<07:20,  3.67s/it]\u001b[A\n",
      " 40%|████████████████████████████████▊                                                | 81/200 [04:40<07:37,  3.85s/it]\u001b[A\n",
      " 41%|█████████████████████████████████▏                                               | 82/200 [04:44<07:25,  3.78s/it]\u001b[A\n",
      " 42%|█████████████████████████████████▌                                               | 83/200 [04:47<07:13,  3.70s/it]\u001b[A\n",
      " 42%|██████████████████████████████████                                               | 84/200 [04:50<06:49,  3.53s/it]\u001b[A\n",
      " 42%|██████████████████████████████████▍                                              | 85/200 [04:54<06:40,  3.48s/it]\u001b[A\n",
      " 43%|██████████████████████████████████▊                                              | 86/200 [04:57<06:31,  3.44s/it]\u001b[A\n",
      " 44%|███████████████████████████████████▏                                             | 87/200 [05:01<06:27,  3.43s/it]\u001b[A\n",
      " 44%|███████████████████████████████████▋                                             | 88/200 [05:04<06:18,  3.38s/it]\u001b[A\n",
      " 44%|████████████████████████████████████                                             | 89/200 [05:07<06:13,  3.37s/it]\u001b[A\n",
      " 45%|████████████████████████████████████▍                                            | 90/200 [05:10<06:06,  3.33s/it]\u001b[A\n",
      " 46%|████████████████████████████████████▊                                            | 91/200 [05:14<06:00,  3.31s/it]\u001b[A\n",
      " 46%|█████████████████████████████████████▎                                           | 92/200 [05:17<05:54,  3.29s/it]\u001b[A\n",
      " 46%|█████████████████████████████████████▋                                           | 93/200 [05:20<05:56,  3.33s/it]\u001b[A\n",
      " 47%|██████████████████████████████████████                                           | 94/200 [05:24<06:03,  3.43s/it]\u001b[A\n",
      " 48%|██████████████████████████████████████▍                                          | 95/200 [05:27<06:00,  3.43s/it]\u001b[A\n",
      " 48%|██████████████████████████████████████▉                                          | 96/200 [05:31<06:10,  3.56s/it]\u001b[A\n",
      " 48%|███████████████████████████████████████▎                                         | 97/200 [05:35<05:58,  3.48s/it]\u001b[A\n",
      " 49%|███████████████████████████████████████▋                                         | 98/200 [05:38<05:49,  3.43s/it]\u001b[A\n",
      " 50%|████████████████████████████████████████                                         | 99/200 [05:42<05:53,  3.50s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████                                        | 100/200 [05:45<05:46,  3.47s/it]\u001b[A\n",
      " 50%|████████████████████████████████████████▍                                       | 101/200 [05:48<05:41,  3.44s/it]\u001b[A\n",
      " 51%|████████████████████████████████████████▊                                       | 102/200 [05:52<05:31,  3.38s/it]\u001b[A\n",
      " 52%|█████████████████████████████████████████▏                                      | 103/200 [05:55<05:19,  3.29s/it]\u001b[A\n",
      " 52%|█████████████████████████████████████████▌                                      | 104/200 [05:58<05:19,  3.33s/it]\u001b[A\n",
      " 52%|██████████████████████████████████████████                                      | 105/200 [06:01<05:16,  3.33s/it]\u001b[A\n",
      " 53%|██████████████████████████████████████████▍                                     | 106/200 [06:05<05:14,  3.35s/it]\u001b[A\n",
      " 54%|██████████████████████████████████████████▊                                     | 107/200 [06:08<05:12,  3.36s/it]\u001b[A\n",
      " 54%|███████████████████████████████████████████▏                                    | 108/200 [06:11<05:05,  3.32s/it]\u001b[A\n",
      " 55%|███████████████████████████████████████████▌                                    | 109/200 [06:15<04:59,  3.29s/it]\u001b[A\n",
      " 55%|████████████████████████████████████████████                                    | 110/200 [06:18<05:02,  3.36s/it]\u001b[A\n",
      " 56%|████████████████████████████████████████████▍                                   | 111/200 [06:22<05:04,  3.42s/it]\u001b[A\n",
      " 56%|████████████████████████████████████████████▊                                   | 112/200 [06:25<04:59,  3.40s/it]\u001b[A\n",
      " 56%|█████████████████████████████████████████████▏                                  | 113/200 [06:28<04:52,  3.37s/it]\u001b[A\n",
      " 57%|█████████████████████████████████████████████▌                                  | 114/200 [06:32<04:45,  3.32s/it]\u001b[A\n",
      " 57%|██████████████████████████████████████████████                                  | 115/200 [06:35<04:45,  3.36s/it]\u001b[A\n",
      " 58%|██████████████████████████████████████████████▍                                 | 116/200 [06:39<04:45,  3.40s/it]\u001b[A\n",
      " 58%|██████████████████████████████████████████████▊                                 | 117/200 [06:42<04:39,  3.37s/it]\u001b[A\n",
      " 59%|███████████████████████████████████████████████▏                                | 118/200 [06:45<04:33,  3.34s/it]\u001b[A\n",
      " 60%|███████████████████████████████████████████████▌                                | 119/200 [06:48<04:29,  3.33s/it]\u001b[A\n",
      " 60%|████████████████████████████████████████████████                                | 120/200 [06:52<04:26,  3.34s/it]\u001b[A\n",
      " 60%|████████████████████████████████████████████████▍                               | 121/200 [06:55<04:28,  3.40s/it]\u001b[A\n",
      " 61%|████████████████████████████████████████████████▊                               | 122/200 [06:59<04:30,  3.47s/it]\u001b[A\n",
      " 62%|█████████████████████████████████████████████████▏                              | 123/200 [07:02<04:27,  3.47s/it]\u001b[A\n",
      " 62%|█████████████████████████████████████████████████▌                              | 124/200 [07:06<04:19,  3.42s/it]\u001b[A\n",
      " 62%|██████████████████████████████████████████████████                              | 125/200 [07:09<04:22,  3.50s/it]\u001b[A\n",
      " 63%|██████████████████████████████████████████████████▍                             | 126/200 [07:13<04:30,  3.66s/it]\u001b[A\n",
      " 64%|██████████████████████████████████████████████████▊                             | 127/200 [07:18<04:35,  3.78s/it]\u001b[A\n",
      " 64%|███████████████████████████████████████████████████▏                            | 128/200 [07:21<04:21,  3.64s/it]\u001b[A\n",
      " 64%|███████████████████████████████████████████████████▌                            | 129/200 [07:24<04:12,  3.55s/it]\u001b[A\n",
      " 65%|████████████████████████████████████████████████████                            | 130/200 [07:27<04:00,  3.43s/it]\u001b[A\n",
      " 66%|████████████████████████████████████████████████████▍                           | 131/200 [07:31<03:53,  3.39s/it]\u001b[A\n",
      " 66%|████████████████████████████████████████████████████▊                           | 132/200 [07:34<03:56,  3.47s/it]\u001b[A\n",
      " 66%|█████████████████████████████████████████████████████▏                          | 133/200 [07:38<03:57,  3.55s/it]\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████▌                          | 134/200 [07:42<03:54,  3.56s/it]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████                          | 135/200 [07:45<03:48,  3.51s/it]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████▍                         | 136/200 [07:48<03:39,  3.43s/it]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████▊                         | 137/200 [07:52<03:34,  3.41s/it]\u001b[A\n",
      " 69%|███████████████████████████████████████████████████████▏                        | 138/200 [07:55<03:33,  3.44s/it]\u001b[A\n",
      " 70%|███████████████████████████████████████████████████████▌                        | 139/200 [07:58<03:27,  3.40s/it]\u001b[A\n",
      " 70%|████████████████████████████████████████████████████████                        | 140/200 [08:02<03:20,  3.35s/it]\u001b[A\n",
      " 70%|████████████████████████████████████████████████████████▍                       | 141/200 [08:05<03:19,  3.37s/it]\u001b[A\n",
      " 71%|████████████████████████████████████████████████████████▊                       | 142/200 [08:09<03:23,  3.50s/it]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████▏                      | 143/200 [08:12<03:18,  3.49s/it]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████▌                      | 144/200 [08:16<03:14,  3.48s/it]\u001b[A\n",
      " 72%|██████████████████████████████████████████████████████████                      | 145/200 [08:19<03:15,  3.55s/it]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████▍                     | 146/200 [08:23<03:08,  3.50s/it]\u001b[A\n",
      " 74%|██████████████████████████████████████████████████████████▊                     | 147/200 [08:26<03:00,  3.41s/it]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████████▏                    | 148/200 [08:30<02:57,  3.42s/it]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████████▌                    | 149/200 [08:33<02:58,  3.51s/it]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████████                    | 150/200 [08:37<02:56,  3.53s/it]\u001b[A\n",
      " 76%|████████████████████████████████████████████████████████████▍                   | 151/200 [08:40<02:50,  3.48s/it]\u001b[A\n",
      " 76%|████████████████████████████████████████████████████████████▊                   | 152/200 [08:44<02:47,  3.49s/it]\u001b[A\n",
      " 76%|█████████████████████████████████████████████████████████████▏                  | 153/200 [08:47<02:46,  3.54s/it]\u001b[A\n",
      " 77%|█████████████████████████████████████████████████████████████▌                  | 154/200 [08:51<02:41,  3.51s/it]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████████                  | 155/200 [08:54<02:35,  3.45s/it]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████████▍                 | 156/200 [08:57<02:29,  3.39s/it]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████████▊                 | 157/200 [09:01<02:25,  3.38s/it]\u001b[A\n",
      " 79%|███████████████████████████████████████████████████████████████▏                | 158/200 [09:04<02:21,  3.37s/it]\u001b[A\n",
      " 80%|███████████████████████████████████████████████████████████████▌                | 159/200 [09:07<02:16,  3.32s/it]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████████                | 160/200 [09:11<02:12,  3.30s/it]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████████▍               | 161/200 [09:14<02:06,  3.25s/it]\u001b[A\n",
      " 81%|████████████████████████████████████████████████████████████████▊               | 162/200 [09:17<02:05,  3.30s/it]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████▏              | 163/200 [09:20<02:03,  3.32s/it]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████▌              | 164/200 [09:24<02:02,  3.40s/it]\u001b[A\n",
      " 82%|██████████████████████████████████████████████████████████████████              | 165/200 [09:28<02:01,  3.48s/it]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████████▍             | 166/200 [09:31<01:58,  3.49s/it]\u001b[A\n",
      " 84%|██████████████████████████████████████████████████████████████████▊             | 167/200 [09:34<01:52,  3.40s/it]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████████▏            | 168/200 [09:38<01:49,  3.43s/it]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████████▌            | 169/200 [09:41<01:44,  3.37s/it]\u001b[A\n",
      " 85%|████████████████████████████████████████████████████████████████████            | 170/200 [09:44<01:38,  3.27s/it]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████▍           | 171/200 [09:47<01:33,  3.23s/it]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████▊           | 172/200 [09:51<01:30,  3.23s/it]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████████████▏          | 173/200 [09:54<01:26,  3.21s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████████▌          | 174/200 [09:57<01:25,  3.30s/it]\u001b[A\n",
      " 88%|██████████████████████████████████████████████████████████████████████          | 175/200 [10:01<01:24,  3.39s/it]\u001b[A\n",
      " 88%|██████████████████████████████████████████████████████████████████████▍         | 176/200 [10:04<01:19,  3.31s/it]\u001b[A\n",
      " 88%|██████████████████████████████████████████████████████████████████████▊         | 177/200 [10:07<01:14,  3.24s/it]\u001b[A\n",
      " 89%|███████████████████████████████████████████████████████████████████████▏        | 178/200 [10:10<01:11,  3.24s/it]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████████████▌        | 179/200 [10:14<01:12,  3.45s/it]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████████        | 180/200 [10:18<01:10,  3.52s/it]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████████▍       | 181/200 [10:22<01:08,  3.62s/it]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████▊       | 182/200 [10:25<01:04,  3.56s/it]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▏      | 183/200 [10:29<01:00,  3.57s/it]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▌      | 184/200 [10:32<00:56,  3.54s/it]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████████      | 185/200 [10:35<00:51,  3.42s/it]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████████▍     | 186/200 [10:39<00:47,  3.38s/it]\u001b[A\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▊     | 187/200 [10:42<00:43,  3.35s/it]\u001b[A\n",
      " 94%|███████████████████████████████████████████████████████████████████████████▏    | 188/200 [10:45<00:39,  3.31s/it]\u001b[A\n",
      " 94%|███████████████████████████████████████████████████████████████████████████▌    | 189/200 [10:48<00:36,  3.29s/it]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████████    | 190/200 [10:52<00:32,  3.28s/it]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▍   | 191/200 [10:55<00:29,  3.32s/it]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▊   | 192/200 [10:58<00:25,  3.23s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████▏  | 193/200 [11:01<00:22,  3.20s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████████████████████████████████████████▌  | 194/200 [11:04<00:19,  3.21s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████  | 195/200 [11:08<00:16,  3.29s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████▍ | 196/200 [11:11<00:13,  3.37s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████▊ | 197/200 [11:15<00:10,  3.43s/it]\u001b[A\n",
      " 99%|███████████████████████████████████████████████████████████████████████████████▏| 198/200 [11:18<00:06,  3.39s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████▌| 199/200 [11:22<00:03,  3.40s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [11:25<00:00,  3.43s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "encoding_model = SentenceTransformer(pretrained_model)\n",
    "similarities_roberta = list()\n",
    "for sentence in tqdm(all_sentences_match_eval) :\n",
    "    sim = list()\n",
    "    e1 = encoding_model.encode(sentence).reshape(1,-1)\n",
    "    for i in range(len(relevant_sentences)) :\n",
    "        e2 = encoding_model.encode(relevant_sentences[i]).reshape(1,-1)\n",
    "        sim = sim + [cosine_similarity(e1, e2)[0][0]]\n",
    "    similarities_roberta.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2960e290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file C:\\Users\\valentin/.cache\\torch\\sentence_transformers\\sentence-transformers_all-MiniLM-L6-v2\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"C:\\\\Users\\\\valentin/.cache\\\\torch\\\\sentence_transformers\\\\sentence-transformers_all-MiniLM-L6-v2\\\\\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file C:\\Users\\valentin/.cache\\torch\\sentence_transformers\\sentence-transformers_all-MiniLM-L6-v2\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "All the weights of BertModel were initialized from the model checkpoint at C:\\Users\\valentin/.cache\\torch\\sentence_transformers\\sentence-transformers_all-MiniLM-L6-v2\\.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "\n",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▍                                                                                 | 1/200 [00:01<05:18,  1.60s/it]\u001b[A\n",
      "  1%|▊                                                                                 | 2/200 [00:03<05:13,  1.58s/it]\u001b[A\n",
      "  2%|█▏                                                                                | 3/200 [00:05<06:13,  1.90s/it]\u001b[A\n",
      "  2%|█▋                                                                                | 4/200 [00:07<06:16,  1.92s/it]\u001b[A\n",
      "  2%|██                                                                                | 5/200 [00:09<06:08,  1.89s/it]\u001b[A\n",
      "  3%|██▍                                                                               | 6/200 [00:11<06:14,  1.93s/it]\u001b[A\n",
      "  4%|██▊                                                                               | 7/200 [00:13<06:10,  1.92s/it]\u001b[A\n",
      "  4%|███▎                                                                              | 8/200 [00:15<06:10,  1.93s/it]\u001b[A\n",
      "  4%|███▋                                                                              | 9/200 [00:16<05:38,  1.77s/it]\u001b[A\n",
      "  5%|████                                                                             | 10/200 [00:17<05:15,  1.66s/it]\u001b[A\n",
      "  6%|████▍                                                                            | 11/200 [00:20<05:39,  1.80s/it]\u001b[A\n",
      "  6%|████▊                                                                            | 12/200 [00:22<05:52,  1.87s/it]\u001b[A\n",
      "  6%|█████▎                                                                           | 13/200 [00:24<05:53,  1.89s/it]\u001b[A\n",
      "  7%|█████▋                                                                           | 14/200 [00:26<06:03,  1.96s/it]\u001b[A\n",
      "  8%|██████                                                                           | 15/200 [00:28<06:06,  1.98s/it]\u001b[A\n",
      "  8%|██████▍                                                                          | 16/200 [00:30<06:07,  2.00s/it]\u001b[A\n",
      "  8%|██████▉                                                                          | 17/200 [00:32<05:59,  1.97s/it]\u001b[A\n",
      "  9%|███████▎                                                                         | 18/200 [00:33<05:53,  1.94s/it]\u001b[A\n",
      " 10%|███████▋                                                                         | 19/200 [00:35<05:36,  1.86s/it]\u001b[A\n",
      " 10%|████████                                                                         | 20/200 [00:37<05:25,  1.81s/it]\u001b[A\n",
      " 10%|████████▌                                                                        | 21/200 [00:39<05:25,  1.82s/it]\u001b[A\n",
      " 11%|████████▉                                                                        | 22/200 [00:41<05:30,  1.86s/it]\u001b[A\n",
      " 12%|█████████▎                                                                       | 23/200 [00:43<05:36,  1.90s/it]\u001b[A\n",
      " 12%|█████████▋                                                                       | 24/200 [00:44<05:29,  1.87s/it]\u001b[A\n",
      " 12%|██████████▏                                                                      | 25/200 [00:47<05:45,  1.98s/it]\u001b[A\n",
      " 13%|██████████▌                                                                      | 26/200 [00:49<05:54,  2.03s/it]\u001b[A\n",
      " 14%|██████████▉                                                                      | 27/200 [00:51<05:55,  2.05s/it]\u001b[A\n",
      " 14%|███████████▎                                                                     | 28/200 [00:53<05:45,  2.01s/it]\u001b[A\n",
      " 14%|███████████▋                                                                     | 29/200 [00:55<05:37,  1.97s/it]\u001b[A\n",
      " 15%|████████████▏                                                                    | 30/200 [00:57<05:34,  1.97s/it]\u001b[A\n",
      " 16%|████████████▌                                                                    | 31/200 [00:58<05:04,  1.80s/it]\u001b[A\n",
      " 16%|████████████▉                                                                    | 32/200 [01:00<05:12,  1.86s/it]\u001b[A\n",
      " 16%|█████████████▎                                                                   | 33/200 [01:02<05:19,  1.92s/it]\u001b[A\n",
      " 17%|█████████████▊                                                                   | 34/200 [01:04<04:53,  1.77s/it]\u001b[A\n",
      " 18%|██████████████▏                                                                  | 35/200 [01:06<05:01,  1.83s/it]\u001b[A\n",
      " 18%|██████████████▌                                                                  | 36/200 [01:08<05:08,  1.88s/it]\u001b[A\n",
      " 18%|██████████████▉                                                                  | 37/200 [01:09<05:08,  1.89s/it]\u001b[A\n",
      " 19%|███████████████▍                                                                 | 38/200 [01:12<05:27,  2.02s/it]\u001b[A\n",
      " 20%|███████████████▊                                                                 | 39/200 [01:14<05:25,  2.02s/it]\u001b[A\n",
      " 20%|████████████████▏                                                                | 40/200 [01:16<05:17,  1.98s/it]\u001b[A\n",
      " 20%|████████████████▌                                                                | 41/200 [01:18<05:16,  1.99s/it]\u001b[A\n",
      " 21%|█████████████████                                                                | 42/200 [01:20<05:15,  2.00s/it]\u001b[A\n",
      " 22%|█████████████████▍                                                               | 43/200 [01:22<05:15,  2.01s/it]\u001b[A\n",
      " 22%|█████████████████▊                                                               | 44/200 [01:24<05:11,  2.00s/it]\u001b[A\n",
      " 22%|██████████████████▏                                                              | 45/200 [01:26<05:15,  2.04s/it]\u001b[A\n",
      " 23%|██████████████████▋                                                              | 46/200 [01:28<05:14,  2.04s/it]\u001b[A\n",
      " 24%|███████████████████                                                              | 47/200 [01:30<05:09,  2.02s/it]\u001b[A\n",
      " 24%|███████████████████▍                                                             | 48/200 [01:32<05:07,  2.02s/it]\u001b[A\n",
      " 24%|███████████████████▊                                                             | 49/200 [01:34<05:12,  2.07s/it]\u001b[A\n",
      " 25%|████████████████████▎                                                            | 50/200 [01:36<04:58,  1.99s/it]\u001b[A\n",
      " 26%|████████████████████▋                                                            | 51/200 [01:38<05:01,  2.02s/it]\u001b[A\n",
      " 26%|█████████████████████                                                            | 52/200 [01:40<04:51,  1.97s/it]\u001b[A\n",
      " 26%|█████████████████████▍                                                           | 53/200 [01:41<04:13,  1.72s/it]\u001b[A\n",
      " 27%|█████████████████████▊                                                           | 54/200 [01:42<03:39,  1.50s/it]\u001b[A\n",
      " 28%|██████████████████████▎                                                          | 55/200 [01:43<03:21,  1.39s/it]\u001b[A\n",
      " 28%|██████████████████████▋                                                          | 56/200 [01:44<03:08,  1.31s/it]\u001b[A\n",
      " 28%|███████████████████████                                                          | 57/200 [01:45<03:01,  1.27s/it]\u001b[A\n",
      " 29%|███████████████████████▍                                                         | 58/200 [01:46<02:44,  1.16s/it]\u001b[A\n",
      " 30%|███████████████████████▉                                                         | 59/200 [01:48<02:51,  1.22s/it]\u001b[A\n",
      " 30%|████████████████████████▎                                                        | 60/200 [01:49<03:06,  1.33s/it]\u001b[A\n",
      " 30%|████████████████████████▋                                                        | 61/200 [01:51<03:03,  1.32s/it]\u001b[A\n",
      " 31%|█████████████████████████                                                        | 62/200 [01:52<03:25,  1.49s/it]\u001b[A\n",
      " 32%|█████████████████████████▌                                                       | 63/200 [01:55<03:55,  1.72s/it]\u001b[A\n",
      " 32%|█████████████████████████▉                                                       | 64/200 [01:57<04:18,  1.90s/it]\u001b[A\n",
      " 32%|██████████████████████████▎                                                      | 65/200 [01:59<04:21,  1.94s/it]\u001b[A\n",
      " 33%|██████████████████████████▋                                                      | 66/200 [02:01<04:16,  1.92s/it]\u001b[A\n",
      " 34%|███████████████████████████▏                                                     | 67/200 [02:03<04:16,  1.93s/it]\u001b[A\n",
      " 34%|███████████████████████████▌                                                     | 68/200 [02:05<04:09,  1.89s/it]\u001b[A\n",
      " 34%|███████████████████████████▉                                                     | 69/200 [02:06<03:41,  1.69s/it]\u001b[A\n",
      " 35%|████████████████████████████▎                                                    | 70/200 [02:07<03:15,  1.51s/it]\u001b[A\n",
      " 36%|████████████████████████████▊                                                    | 71/200 [02:09<03:26,  1.60s/it]\u001b[A\n",
      " 36%|█████████████████████████████▏                                                   | 72/200 [02:10<03:15,  1.53s/it]\u001b[A\n",
      " 36%|█████████████████████████████▌                                                   | 73/200 [02:12<03:24,  1.61s/it]\u001b[A\n",
      " 37%|█████████████████████████████▉                                                   | 74/200 [02:13<03:10,  1.51s/it]\u001b[A\n",
      " 38%|██████████████████████████████▍                                                  | 75/200 [02:15<03:09,  1.51s/it]\u001b[A\n",
      " 38%|██████████████████████████████▊                                                  | 76/200 [02:17<03:28,  1.68s/it]\u001b[A\n",
      " 38%|███████████████████████████████▏                                                 | 77/200 [02:18<03:18,  1.61s/it]\u001b[A\n",
      " 39%|███████████████████████████████▌                                                 | 78/200 [02:20<03:13,  1.59s/it]\u001b[A\n",
      " 40%|███████████████████████████████▉                                                 | 79/200 [02:21<02:48,  1.39s/it]\u001b[A\n",
      " 40%|████████████████████████████████▍                                                | 80/200 [02:22<02:53,  1.45s/it]\u001b[A\n",
      " 40%|████████████████████████████████▊                                                | 81/200 [02:24<02:53,  1.46s/it]\u001b[A\n",
      " 41%|█████████████████████████████████▏                                               | 82/200 [02:25<02:53,  1.47s/it]\u001b[A\n",
      " 42%|█████████████████████████████████▌                                               | 83/200 [02:27<03:03,  1.56s/it]\u001b[A\n",
      " 42%|██████████████████████████████████                                               | 84/200 [02:29<03:17,  1.70s/it]\u001b[A\n",
      " 42%|██████████████████████████████████▍                                              | 85/200 [02:31<03:23,  1.77s/it]\u001b[A\n",
      " 43%|██████████████████████████████████▊                                              | 86/200 [02:33<03:31,  1.86s/it]\u001b[A\n",
      " 44%|███████████████████████████████████▏                                             | 87/200 [02:35<03:31,  1.87s/it]\u001b[A\n",
      " 44%|███████████████████████████████████▋                                             | 88/200 [02:37<03:34,  1.92s/it]\u001b[A\n",
      " 44%|████████████████████████████████████                                             | 89/200 [02:39<03:33,  1.92s/it]\u001b[A\n",
      " 45%|████████████████████████████████████▍                                            | 90/200 [02:41<03:25,  1.87s/it]\u001b[A\n",
      " 46%|████████████████████████████████████▊                                            | 91/200 [02:43<03:23,  1.87s/it]\u001b[A\n",
      " 46%|█████████████████████████████████████▎                                           | 92/200 [02:44<03:14,  1.80s/it]\u001b[A\n",
      " 46%|█████████████████████████████████████▋                                           | 93/200 [02:46<03:17,  1.85s/it]\u001b[A\n",
      " 47%|██████████████████████████████████████                                           | 94/200 [02:48<03:22,  1.91s/it]\u001b[A\n",
      " 48%|██████████████████████████████████████▍                                          | 95/200 [02:50<03:17,  1.88s/it]\u001b[A\n",
      " 48%|██████████████████████████████████████▉                                          | 96/200 [02:52<03:23,  1.95s/it]\u001b[A\n",
      " 48%|███████████████████████████████████████▎                                         | 97/200 [02:54<03:24,  1.99s/it]\u001b[A\n",
      " 49%|███████████████████████████████████████▋                                         | 98/200 [02:56<03:19,  1.96s/it]\u001b[A\n",
      " 50%|████████████████████████████████████████                                         | 99/200 [02:58<03:16,  1.95s/it]\u001b[A\n",
      " 50%|████████████████████████████████████████                                        | 100/200 [02:59<02:49,  1.69s/it]\u001b[A\n",
      " 50%|████████████████████████████████████████▍                                       | 101/200 [03:00<02:35,  1.57s/it]\u001b[A\n",
      " 51%|████████████████████████████████████████▊                                       | 102/200 [03:02<02:34,  1.58s/it]\u001b[A\n",
      " 52%|█████████████████████████████████████████▏                                      | 103/200 [03:04<02:40,  1.65s/it]\u001b[A\n",
      " 52%|█████████████████████████████████████████▌                                      | 104/200 [03:06<02:43,  1.71s/it]\u001b[A\n",
      " 52%|██████████████████████████████████████████                                      | 105/200 [03:07<02:38,  1.67s/it]\u001b[A\n",
      " 53%|██████████████████████████████████████████▍                                     | 106/200 [03:09<02:52,  1.84s/it]\u001b[A\n",
      " 54%|██████████████████████████████████████████▊                                     | 107/200 [03:11<02:54,  1.87s/it]\u001b[A\n",
      " 54%|███████████████████████████████████████████▏                                    | 108/200 [03:13<02:54,  1.90s/it]\u001b[A\n",
      " 55%|███████████████████████████████████████████▌                                    | 109/200 [03:15<02:53,  1.90s/it]\u001b[A\n",
      " 55%|████████████████████████████████████████████                                    | 110/200 [03:17<02:52,  1.91s/it]\u001b[A\n",
      " 56%|████████████████████████████████████████████▍                                   | 111/200 [03:19<02:54,  1.96s/it]\u001b[A\n",
      " 56%|████████████████████████████████████████████▊                                   | 112/200 [03:22<03:01,  2.06s/it]\u001b[A\n",
      " 56%|█████████████████████████████████████████████▏                                  | 113/200 [03:24<03:08,  2.16s/it]\u001b[A\n",
      " 57%|█████████████████████████████████████████████▌                                  | 114/200 [03:25<02:48,  1.96s/it]\u001b[A\n",
      " 57%|██████████████████████████████████████████████                                  | 115/200 [03:27<02:24,  1.71s/it]\u001b[A\n",
      " 58%|██████████████████████████████████████████████▍                                 | 116/200 [03:28<02:08,  1.53s/it]\u001b[A\n",
      " 58%|██████████████████████████████████████████████▊                                 | 117/200 [03:29<02:01,  1.47s/it]\u001b[A\n",
      " 59%|███████████████████████████████████████████████▏                                | 118/200 [03:31<02:09,  1.57s/it]\u001b[A\n",
      " 60%|███████████████████████████████████████████████▌                                | 119/200 [03:32<02:00,  1.49s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████                                | 120/200 [03:34<01:56,  1.46s/it]\u001b[A\n",
      " 60%|████████████████████████████████████████████████▍                               | 121/200 [03:35<02:06,  1.60s/it]\u001b[A\n",
      " 61%|████████████████████████████████████████████████▊                               | 122/200 [03:38<02:15,  1.73s/it]\u001b[A\n",
      " 62%|█████████████████████████████████████████████████▏                              | 123/200 [03:39<02:15,  1.76s/it]\u001b[A\n",
      " 62%|█████████████████████████████████████████████████▌                              | 124/200 [03:41<02:03,  1.62s/it]\u001b[A\n",
      " 62%|██████████████████████████████████████████████████                              | 125/200 [03:42<02:01,  1.62s/it]\u001b[A\n",
      " 63%|██████████████████████████████████████████████████▍                             | 126/200 [03:43<01:49,  1.48s/it]\u001b[A\n",
      " 64%|██████████████████████████████████████████████████▊                             | 127/200 [03:45<01:54,  1.57s/it]\u001b[A\n",
      " 64%|███████████████████████████████████████████████████▏                            | 128/200 [03:47<01:55,  1.60s/it]\u001b[A\n",
      " 64%|███████████████████████████████████████████████████▌                            | 129/200 [03:48<01:49,  1.54s/it]\u001b[A\n",
      " 65%|████████████████████████████████████████████████████                            | 130/200 [03:50<01:46,  1.52s/it]\u001b[A\n",
      " 66%|████████████████████████████████████████████████████▍                           | 131/200 [03:52<01:55,  1.68s/it]\u001b[A\n",
      " 66%|████████████████████████████████████████████████████▊                           | 132/200 [03:54<02:05,  1.85s/it]\u001b[A\n",
      " 66%|█████████████████████████████████████████████████████▏                          | 133/200 [03:56<02:08,  1.92s/it]\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████▌                          | 134/200 [03:58<02:04,  1.88s/it]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████                          | 135/200 [04:00<02:06,  1.95s/it]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████▍                         | 136/200 [04:02<01:56,  1.82s/it]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████▊                         | 137/200 [04:03<01:56,  1.86s/it]\u001b[A\n",
      " 69%|███████████████████████████████████████████████████████▏                        | 138/200 [04:05<01:56,  1.88s/it]\u001b[A\n",
      " 70%|███████████████████████████████████████████████████████▌                        | 139/200 [04:07<01:54,  1.88s/it]\u001b[A\n",
      " 70%|████████████████████████████████████████████████████████                        | 140/200 [04:09<01:54,  1.90s/it]\u001b[A\n",
      " 70%|████████████████████████████████████████████████████████▍                       | 141/200 [04:11<01:55,  1.96s/it]\u001b[A\n",
      " 71%|████████████████████████████████████████████████████████▊                       | 142/200 [04:13<01:50,  1.91s/it]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████▏                      | 143/200 [04:15<01:48,  1.91s/it]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████▌                      | 144/200 [04:17<01:42,  1.83s/it]\u001b[A\n",
      " 72%|██████████████████████████████████████████████████████████                      | 145/200 [04:19<01:40,  1.83s/it]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████▍                     | 146/200 [04:20<01:35,  1.76s/it]\u001b[A\n",
      " 74%|██████████████████████████████████████████████████████████▊                     | 147/200 [04:22<01:37,  1.84s/it]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████████▏                    | 148/200 [04:24<01:34,  1.82s/it]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████████▌                    | 149/200 [04:26<01:30,  1.77s/it]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████████                    | 150/200 [04:28<01:33,  1.87s/it]\u001b[A\n",
      " 76%|████████████████████████████████████████████████████████████▍                   | 151/200 [04:30<01:32,  1.90s/it]\u001b[A\n",
      " 76%|████████████████████████████████████████████████████████████▊                   | 152/200 [04:32<01:33,  1.95s/it]\u001b[A\n",
      " 76%|█████████████████████████████████████████████████████████████▏                  | 153/200 [04:34<01:30,  1.94s/it]\u001b[A\n",
      " 77%|█████████████████████████████████████████████████████████████▌                  | 154/200 [04:36<01:30,  1.97s/it]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████████                  | 155/200 [04:38<01:30,  2.01s/it]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████████▍                 | 156/200 [04:40<01:28,  2.01s/it]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████████▊                 | 157/200 [04:41<01:21,  1.91s/it]\u001b[A\n",
      " 79%|███████████████████████████████████████████████████████████████▏                | 158/200 [04:43<01:21,  1.95s/it]\u001b[A\n",
      " 80%|███████████████████████████████████████████████████████████████▌                | 159/200 [04:46<01:22,  2.01s/it]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████████                | 160/200 [04:47<01:09,  1.73s/it]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████████▍               | 161/200 [04:48<01:07,  1.74s/it]\u001b[A\n",
      " 81%|████████████████████████████████████████████████████████████████▊               | 162/200 [04:50<01:06,  1.76s/it]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████▏              | 163/200 [04:52<01:08,  1.86s/it]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████▌              | 164/200 [04:54<01:05,  1.82s/it]\u001b[A\n",
      " 82%|██████████████████████████████████████████████████████████████████              | 165/200 [04:56<01:02,  1.80s/it]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████████▍             | 166/200 [04:58<01:04,  1.88s/it]\u001b[A\n",
      " 84%|██████████████████████████████████████████████████████████████████▊             | 167/200 [05:00<01:00,  1.83s/it]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████████▏            | 168/200 [05:02<01:00,  1.90s/it]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████████▌            | 169/200 [05:03<00:56,  1.81s/it]\u001b[A\n",
      " 85%|████████████████████████████████████████████████████████████████████            | 170/200 [05:05<00:55,  1.85s/it]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████▍           | 171/200 [05:07<00:52,  1.81s/it]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████▊           | 172/200 [05:09<00:52,  1.88s/it]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████████████▏          | 173/200 [05:11<00:50,  1.87s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████████▌          | 174/200 [05:13<00:49,  1.91s/it]\u001b[A\n",
      " 88%|██████████████████████████████████████████████████████████████████████          | 175/200 [05:14<00:42,  1.71s/it]\u001b[A\n",
      " 88%|██████████████████████████████████████████████████████████████████████▍         | 176/200 [05:15<00:38,  1.62s/it]\u001b[A\n",
      " 88%|██████████████████████████████████████████████████████████████████████▊         | 177/200 [05:17<00:38,  1.68s/it]\u001b[A\n",
      " 89%|███████████████████████████████████████████████████████████████████████▏        | 178/200 [05:19<00:35,  1.62s/it]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████████████▌        | 179/200 [05:21<00:36,  1.76s/it]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████████        | 180/200 [05:23<00:35,  1.78s/it]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████████▍       | 181/200 [05:24<00:32,  1.73s/it]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████▊       | 182/200 [05:26<00:31,  1.73s/it]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▏      | 183/200 [05:28<00:28,  1.68s/it]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▌      | 184/200 [05:30<00:28,  1.79s/it]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████████      | 185/200 [05:31<00:26,  1.79s/it]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████████▍     | 186/200 [05:33<00:25,  1.82s/it]\u001b[A\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▊     | 187/200 [05:36<00:25,  1.95s/it]\u001b[A\n",
      " 94%|███████████████████████████████████████████████████████████████████████████▏    | 188/200 [05:37<00:21,  1.80s/it]\u001b[A\n",
      " 94%|███████████████████████████████████████████████████████████████████████████▌    | 189/200 [05:38<00:17,  1.62s/it]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████████    | 190/200 [05:40<00:16,  1.62s/it]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▍   | 191/200 [05:41<00:14,  1.58s/it]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▊   | 192/200 [05:43<00:12,  1.55s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████▏  | 193/200 [05:44<00:11,  1.58s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████████████████████████████████████████▌  | 194/200 [05:46<00:09,  1.58s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████  | 195/200 [05:48<00:08,  1.64s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████▍ | 196/200 [05:50<00:06,  1.65s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████▊ | 197/200 [05:51<00:05,  1.68s/it]\u001b[A\n",
      " 99%|███████████████████████████████████████████████████████████████████████████████▏| 198/200 [05:53<00:03,  1.73s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████▌| 199/200 [05:55<00:01,  1.70s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [05:56<00:00,  1.78s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "encoding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "similarities_miniLM = list()\n",
    "for sentence in tqdm(all_sentences_match_eval) :\n",
    "    sim = list()\n",
    "    e1 = encoding_model.encode(sentence).reshape(1,-1)\n",
    "    for i in range(len(relevant_sentences)) :\n",
    "        e2 = encoding_model.encode(relevant_sentences[i]).reshape(1,-1)\n",
    "        sim = sim + [cosine_similarity(e1, e2)[0][0]]\n",
    "    similarities_miniLM.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d38980ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim = pd.DataFrame({\"sim_miniLM_mean\" : [np.mean(x) for x in similarities_miniLM],\n",
    "                      \"sim_miniLM_max\" : [np.max(x) for x in similarities_miniLM],\n",
    "                      \"sim_roberta\" : [np.mean(x) for x in similarities_roberta],\n",
    "                       \"sim_roberta_max\" : [np.max(x) for x in similarities_roberta]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8e3a90ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = pd.concat([df_analysis, df_sim], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a678c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.to_excel(\"df_analysis.xlsx\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
