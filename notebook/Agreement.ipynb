{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2880d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculating annotators agreements during the annotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4b063d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c913818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e53d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times each category was chosen for each item\n",
    "def count_categories(ratings, num_categories):\n",
    "    counts = np.zeros((ratings.shape[0], num_categories), dtype=int)\n",
    "    for i, item_ratings in enumerate(ratings):\n",
    "        for rating in item_ratings:\n",
    "            counts[i, rating - 1] += 1  # Assuming categories are 1-indexed\n",
    "    return counts\n",
    "\n",
    "def FleissKappa(annotation_round, corpus) :\n",
    "    if annotation_round > 0 :\n",
    "        df_round = corpus[corpus['annotation_round'] == annotation_round]\n",
    "        corpus_array = df_round[['A1','A2','A3']].to_numpy()\n",
    "        num_categories = len(set(corpus_array.flatten()))\n",
    "        category_counts = count_categories(corpus_array, num_categories)\n",
    "        kappa = fleiss_kappa(category_counts)\n",
    "        print(\"Fleiss' Kappa score : {} for round {}\".format(kappa, annotation_round))\n",
    "    else :\n",
    "        corpus_array = corpus[['A1','A2','A3']].to_numpy()\n",
    "        num_categories = len(set(corpus_array.flatten()))\n",
    "        category_counts = count_categories(corpus_array, num_categories)\n",
    "        kappa = fleiss_kappa(category_counts)\n",
    "        print(\"Fleiss' Kappa score : {} for the whole dataset\".format(kappa))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24900320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa(annotation_round, corpus) :\n",
    "    if annotation_round > 0 :\n",
    "        df_round = corpus[corpus['annotation_round'] == annotation_round]\n",
    "        y1 = df_round['A1'].tolist()\n",
    "        y2 = df_round['A2'].tolist()\n",
    "        y3 = df_round['A3'].tolist()\n",
    "        print(\"Kappa score between A1 and A2 : {} for round {}\".format(cohen_kappa_score(y1, y2), annotation_round))\n",
    "        print(\"Kappa score between A1 and A3 : {} for round {}\".format(cohen_kappa_score(y1, y3), annotation_round))\n",
    "        print(\"Kappa score between A2 and A3 : {} for round {}\".format(cohen_kappa_score(y2, y3), annotation_round))\n",
    "    else :\n",
    "        y1 = corpus['A1'].tolist()\n",
    "        y2 = corpus['A2'].tolist()\n",
    "        y3 = corpus['A3'].tolist()\n",
    "        print(\"Kappa score between A1 and A2 : {} for the whole dataset\".format(cohen_kappa_score(y1, y2)))\n",
    "        print(\"Kappa score between A1 and A3 : {} for the whole dataset\".format(cohen_kappa_score(y1, y3)))\n",
    "        print(\"Kappa score between A2 and A3 : {} for the whole dataset\".format(cohen_kappa_score(y2, y3)))\n",
    "\n",
    "\n",
    "def kappa_final(annotation_round, corpus) :\n",
    "    if annotation_round > 0 :\n",
    "        df_round = corpus[corpus['annotation_round'] == annotation_round]\n",
    "        y1 = df_round['A1'].tolist()\n",
    "        y2 = df_round['A2'].tolist()\n",
    "        y3 = df_round['A3'].tolist()\n",
    "        final = df_round['FINAL'].tolist()\n",
    "        print(\"Kappa score between A1 and final label : {} for round {}\".format(cohen_kappa_score(y1, final), annotation_round))\n",
    "        print(\"Kappa score between A2 and final label : {} for round {}\".format(cohen_kappa_score(y2, final), annotation_round))\n",
    "        print(\"Kappa score between A3 and final label : {} for round {}\".format(cohen_kappa_score(y3, final), annotation_round))\n",
    "    else : \n",
    "        y1 = corpus['A1'].tolist()\n",
    "        y2 = corpus['A2'].tolist()\n",
    "        y3 = corpus['A3'].tolist()\n",
    "        final = corpus['relevance_label'].tolist()\n",
    "        print(\"Kappa score between A1 and final label : {} for the whole dataset\".format(cohen_kappa_score(y1, final)))\n",
    "        print(\"Kappa score between A2 and final label : {} for the whole dataset\".format(cohen_kappa_score(y2, final)))\n",
    "        print(\"Kappa score between A3 and final label : {} for the whole dataset\".format(cohen_kappa_score(y3, final)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "463f986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agreement_score(annotation_round, corpus) :\n",
    "    if annotation_round > 0 :\n",
    "        df_round = corpus[corpus['annotation_round'] == annotation_round]\n",
    "        agreement = df_round[(df_round['A1'] == df_round['A2']) & (df_round['A2'] == df_round['A3'])]\n",
    "        print(\"Agreement score : {} for round {}\".format(len(agreement.index)*100/len(df_round.index), annotation_round))\n",
    "    else:\n",
    "        agreement = corpus[(corpus['A1'] == corpus['A2']) & (corpus['A2'] == corpus['A3'])]\n",
    "        print(\"Agreement score : {} for the whole dataset\".format(len(agreement.index)*100/len(corpus.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "549520d4-6238-46c0-9625-55b6712f9831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agreement_score2(corpus) :\n",
    "    agreement = corpus[(corpus['A2'] == corpus['A3'])]\n",
    "    print(\"Agreement score : {}\".format(len(agreement.index)*100/len(corpus.index)))\n",
    "\n",
    "def kappa_2(corpus) :\n",
    "    y2 = corpus['A2'].tolist()\n",
    "    y3 = corpus['A3'].tolist()\n",
    "    final = corpus['relevance_label'].tolist()\n",
    "    print(\"Kappa score between A2 and A3 : {}\".format(cohen_kappa_score(y2, y3)))\n",
    "    print(\"Kappa score between A2 and final label : {}\".format(cohen_kappa_score(y2, final)))\n",
    "    print(\"Kappa score between A3 and final label : {}\".format(cohen_kappa_score(y3, final)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67325496",
   "metadata": {},
   "source": [
    "## 1. Inter-annotator agreement, 3 annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60a260c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_segment</th>\n",
       "      <th>id_segment_old</th>\n",
       "      <th>text_segment</th>\n",
       "      <th>annotation_round</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>relevance_label</th>\n",
       "      <th>relevance_type_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-s2.0-S0301479717300713-main_99</td>\n",
       "      <td>1-s2.0-S0301479717300713-main.pdf.tei_48</td>\n",
       "      <td>In total, 12 documents were identified as rele...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-s2.0-S0304387816300670-main_355</td>\n",
       "      <td>1-s2.0-S0304387816300670-main.pdf.tei_119</td>\n",
       "      <td>While our model and the specification below fo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-s2.0-S0140196313000608-main_210</td>\n",
       "      <td>1-s2.0-S0140196313000608-main.pdf.tei_110</td>\n",
       "      <td>Other areas have experienced a decrease in [cr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LULCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-s2.0-S0169204617300270-main_74</td>\n",
       "      <td>1-s2.0-S0169204617300270-main.pdf.tei_35</td>\n",
       "      <td>We use the term \"[urban] sprawl\" to describe a...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-s2.0-S095937809800003X-main_240</td>\n",
       "      <td>1-s2.0-S095937809800003X-main.pdf.tei_69</td>\n",
       "      <td>Thus, changes in [land use] strategies result ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>PRACTICES, LULCC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id_segment  \\\n",
       "0   1-s2.0-S0301479717300713-main_99   \n",
       "1  1-s2.0-S0304387816300670-main_355   \n",
       "2  1-s2.0-S0140196313000608-main_210   \n",
       "3   1-s2.0-S0169204617300270-main_74   \n",
       "4  1-s2.0-S095937809800003X-main_240   \n",
       "\n",
       "                              id_segment_old  \\\n",
       "0   1-s2.0-S0301479717300713-main.pdf.tei_48   \n",
       "1  1-s2.0-S0304387816300670-main.pdf.tei_119   \n",
       "2  1-s2.0-S0140196313000608-main.pdf.tei_110   \n",
       "3   1-s2.0-S0169204617300270-main.pdf.tei_35   \n",
       "4   1-s2.0-S095937809800003X-main.pdf.tei_69   \n",
       "\n",
       "                                        text_segment  annotation_round  A1  \\\n",
       "0  In total, 12 documents were identified as rele...                 1   1   \n",
       "1  While our model and the specification below fo...                 1   1   \n",
       "2  Other areas have experienced a decrease in [cr...                 1   1   \n",
       "3  We use the term \"[urban] sprawl\" to describe a...                 1   2   \n",
       "4  Thus, changes in [land use] strategies result ...                 1   1   \n",
       "\n",
       "   A2  A3  relevance_label relevance_type_norm  \n",
       "0   0   0                0                 NaN  \n",
       "1   0   0                0                 NaN  \n",
       "2   2   1                1               LULCC  \n",
       "3   0   0                0                 NaN  \n",
       "4   2   2                2    PRACTICES, LULCC  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel = \"corpus_three_annot.xlsx\"\n",
    "corpus_three_annot = pd.read_excel(excel)\n",
    "corpus_three_annot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2523b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_three_annot_12 = corpus_three_annot.copy()\n",
    "corpus_three_annot_12[['A1', 'A2', 'A3','relevance_label']] = corpus_three_annot_12[['A1', 'A2', 'A3','relevance_label']].replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2953358",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_three_annot['A1'] = corpus_three_annot['A1'].apply(lambda x: int(x))\n",
    "corpus_three_annot['A2'] = corpus_three_annot['A2'].apply(lambda x: int(x))\n",
    "corpus_three_annot['A3'] = corpus_three_annot['A3'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d4cc64",
   "metadata": {},
   "source": [
    "### 1.1. Classes 1 & 2 separated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec44c57",
   "metadata": {},
   "source": [
    "#### Fleiss Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "097bd790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fleiss' Kappa score : 0.29908376963350775 for round 1\n",
      "Fleiss' Kappa score : 0.4191406970311634 for round 2\n",
      "Fleiss' Kappa score : 0.4184073107049608 for round 3\n",
      "Fleiss' Kappa score : 0.3929715117488043 for the whole dataset\n"
     ]
    }
   ],
   "source": [
    "FleissKappa(1, corpus = corpus_three_annot)\n",
    "FleissKappa(2, corpus = corpus_three_annot)\n",
    "FleissKappa(3, corpus = corpus_three_annot)\n",
    "FleissKappa(0, corpus = corpus_three_annot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6acab2",
   "metadata": {},
   "source": [
    "#### Agreement score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdf7a6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement score : 33.333333333333336 for round 1\n"
     ]
    }
   ],
   "source": [
    "agreement_score(annotation_round = 1, corpus = corpus_three_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21cf66b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement score : 60.0 for round 2\n"
     ]
    }
   ],
   "source": [
    "agreement_score(annotation_round = 2, corpus = corpus_three_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1672d20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement score : 49.20634920634921 for round 3\n"
     ]
    }
   ],
   "source": [
    "agreement_score(annotation_round = 3, corpus = corpus_three_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e52a4a1-ed06-4f05-a0b4-239843150a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement score : 47.5609756097561 for the whole dataset\n"
     ]
    }
   ],
   "source": [
    "agreement_score(annotation_round = 0, corpus = corpus_three_annot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6837c2",
   "metadata": {},
   "source": [
    "### 1.2. Classes 1 & 2 merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0543e889",
   "metadata": {},
   "source": [
    "#### Fleiss Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d6dae4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fleiss' Kappa score : 0.3045454545454547 for round 1\n",
      "Fleiss' Kappa score : 0.4485294117647058 for round 2\n",
      "Fleiss' Kappa score : 0.5321782178217822 for round 3\n",
      "Fleiss' Kappa score : 0.45908848614072506 for the whole dataset\n"
     ]
    }
   ],
   "source": [
    "FleissKappa(1, corpus = corpus_three_annot_12)\n",
    "FleissKappa(2, corpus = corpus_three_annot_12)\n",
    "FleissKappa(3, corpus = corpus_three_annot_12)\n",
    "FleissKappa(0, corpus = corpus_three_annot_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a775bda",
   "metadata": {},
   "source": [
    "#### Agreement score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e64c6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement score : 49.01960784313726 for round 1\n"
     ]
    }
   ],
   "source": [
    "agreement_score(annotation_round = 1, corpus = corpus_three_annot_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ee7bd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement score : 64.0 for round 2\n"
     ]
    }
   ],
   "source": [
    "agreement_score(annotation_round = 2, corpus = corpus_three_annot_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4b2d211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement score : 65.07936507936508 for round 3\n"
     ]
    }
   ],
   "source": [
    "agreement_score(annotation_round = 3, corpus = corpus_three_annot_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "559e5192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement score : 59.75609756097561 for the whole dataset\n"
     ]
    }
   ],
   "source": [
    "agreement_score(annotation_round = 0, corpus = corpus_three_annot_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f864b7-178a-4150-aaf2-a0f8b00d991a",
   "metadata": {},
   "source": [
    "## 2. Inter-annotator agreement, 2 annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c34806e-38ff-4ded-840f-24fff126ad0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_segment</th>\n",
       "      <th>id_segment_old</th>\n",
       "      <th>text_segment</th>\n",
       "      <th>A2</th>\n",
       "      <th>relevance_type_A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>relevance_type_A3</th>\n",
       "      <th>relevance_type</th>\n",
       "      <th>relevance_label</th>\n",
       "      <th>relevance_type_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-s2.0-S0304387816300670-main_112</td>\n",
       "      <td>1-s2.0-S0301479717300713-main.pdf.tei_82</td>\n",
       "      <td>(2004)'}], '#text': 'With regard to population...</td>\n",
       "      <td>1</td>\n",
       "      <td>DRIVERS</td>\n",
       "      <td>2</td>\n",
       "      <td>Drivers</td>\n",
       "      <td>DRIVERS</td>\n",
       "      <td>1</td>\n",
       "      <td>DRIVERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-s2.0-S235198941500102X-main_233</td>\n",
       "      <td>1-s2.0-S235198941500102X-main.pdf.tei_62</td>\n",
       "      <td>(%)', '100', '37.25', '93.25', '75.58', '94.24...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>TABLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s10113-015-0891-1_24</td>\n",
       "      <td>1-s2.0-S0168192311001122-main.pdf.tei_80</td>\n",
       "      <td>On the other hand, whereas the combination of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-s2.0-S0167880913003502-main_358</td>\n",
       "      <td>1-s2.0-S0167880913003502-main.pdf.tei_123</td>\n",
       "      <td>Whilst Blanco-Canqui and stress those similar ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-s2.0-S030438781000043X-mainext_610</td>\n",
       "      <td>1-s2.0-S030438781000043X-mainext.pdf.tei_75</td>\n",
       "      <td>In addition to land ownership, the regressions...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id_segment  \\\n",
       "0     1-s2.0-S0304387816300670-main_112   \n",
       "1     1-s2.0-S235198941500102X-main_233   \n",
       "2                  s10113-015-0891-1_24   \n",
       "3     1-s2.0-S0167880913003502-main_358   \n",
       "4  1-s2.0-S030438781000043X-mainext_610   \n",
       "\n",
       "                                id_segment_old  \\\n",
       "0     1-s2.0-S0301479717300713-main.pdf.tei_82   \n",
       "1     1-s2.0-S235198941500102X-main.pdf.tei_62   \n",
       "2     1-s2.0-S0168192311001122-main.pdf.tei_80   \n",
       "3    1-s2.0-S0167880913003502-main.pdf.tei_123   \n",
       "4  1-s2.0-S030438781000043X-mainext.pdf.tei_75   \n",
       "\n",
       "                                        text_segment  A2 relevance_type_A2  \\\n",
       "0  (2004)'}], '#text': 'With regard to population...   1           DRIVERS   \n",
       "1  (%)', '100', '37.25', '93.25', '75.58', '94.24...   0               NaN   \n",
       "2  On the other hand, whereas the combination of ...   0               NaN   \n",
       "3  Whilst Blanco-Canqui and stress those similar ...   0               NaN   \n",
       "4  In addition to land ownership, the regressions...   0               NaN   \n",
       "\n",
       "   A3 relevance_type_A3 relevance_type  relevance_label relevance_type_norm  \n",
       "0   2           Drivers        DRIVERS                1             DRIVERS  \n",
       "1   0             TABLE            NaN                0                 NaN  \n",
       "2   0               NaN            NaN                0                 NaN  \n",
       "3   0               NaN            NaN                0                 NaN  \n",
       "4   0               NaN            NaN                0                 NaN  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel = \"corpus_two_annot.xlsx\"\n",
    "corpus_two_annot = pd.read_excel(excel)\n",
    "corpus_two_annot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2177f82",
   "metadata": {},
   "source": [
    "### 2.1. Classes 1 & 2 separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cbb405e0-89c5-477d-bf60-bc18c8243195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa score between A2 and A3 : 0.6989473684210525\n",
      "Kappa score between A2 and final label : 0.8519079104596511\n",
      "Kappa score between A3 and final label : 0.8484304932735426\n"
     ]
    }
   ],
   "source": [
    "kappa_2(corpus_two_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c2723a3-8659-482e-aebd-d5f0dc5930f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement score : 86.98224852071006\n"
     ]
    }
   ],
   "source": [
    "agreement_score2(corpus_two_annot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c366770-7e0e-44df-b90e-5166380104d7",
   "metadata": {},
   "source": [
    "### 2.2. Classes 1 & 2 merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54a0afb6-23f4-449b-8a83-23fb44bb003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_two_annot_12 = corpus_two_annot.copy()\n",
    "corpus_two_annot_12[['A2', 'A3','relevance_label']] = corpus_two_annot_12[[ 'A2', 'A3','relevance_label']].replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a95b0d48-3ad4-4888-b42d-d564d17e9fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa score between A2 and A3 : 0.8208163986570065\n",
      "Kappa score between A2 and final label : 0.9115800488315312\n",
      "Kappa score between A3 and final label : 0.9104081993285033\n",
      "Agreement score : 92.89940828402366\n"
     ]
    }
   ],
   "source": [
    "kappa_2(corpus=corpus_two_annot_12)\n",
    "agreement_score2(corpus=corpus_two_annot_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43ce7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
